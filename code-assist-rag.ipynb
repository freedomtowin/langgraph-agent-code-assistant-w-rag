{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2081d499-bbde-4476-9e58-34d62ed902d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from retriever import create_vector_store\n",
    "\n",
    "url = \"https://docs.python.org/3/library/re.html\"\n",
    "\n",
    "retriever = create_vector_store(url = url, k = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8cd705-9e9f-4fe4-9ce8-5191dcb13a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "expt_llm = \"gpt-4o\"\n",
    "llm = ChatOpenAI(model=expt_llm, max_tokens=4096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0657ff9e-a3f1-438b-8f75-d964f32f5d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rag_agent import create_rag_agent\n",
    "\n",
    "retrieval_grader = create_rag_agent(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "019542ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from code_agent import create_code_agent\n",
    "\n",
    "code_gen_chain_oai = create_code_agent(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "76537eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graph_state import GraphState\n",
    "\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "68603379",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "\n",
    "# Rag nodes\n",
    "def retrieve(state):\n",
    "    \"\"\"\n",
    "    Retrieve documents\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, documents, that contains retrieved documents\n",
    "    \"\"\"\n",
    "    print(\"---RETRIEVE---\")\n",
    "    question = state[\"messages\"][0][1]\n",
    "    test_cases = state[\"test_cases\"]\n",
    "\n",
    "    # Retrieval\n",
    "    documents = retriever.invoke(question)\n",
    "    return {\"documents\": documents[:], \"test_cases\": test_cases}\n",
    "\n",
    "def grade_documents(state):\n",
    "    \"\"\"\n",
    "    Determines whether the retrieved documents are relevant to the question.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): Updates documents key with only filtered relevant documents\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---CHECK DOCUMENT RELEVANCE TO QUESTION---\")\n",
    "    question = state[\"messages\"][0][1]\n",
    "    error = state[\"error\"]\n",
    "    \n",
    "    # If there was an error, add to the question\n",
    "    if error == \"yes\":\n",
    "        question += \"\\n\\n\"\n",
    "        question += \"\\n\\n\".join([msg[1] for msg in state[\"messages\"][-3:]])\n",
    "\n",
    "    print(question)\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    # Score each doc\n",
    "    filtered_docs = []\n",
    "    for d in documents:\n",
    "        score = retrieval_grader.invoke(\n",
    "            {\"question\": question, \"document\": d.page_content}\n",
    "        )\n",
    "        grade = score[\"score\"]\n",
    "        if grade == \"yes\":\n",
    "            print(\"---GRADE: DOCUMENT RELEVANT---\")\n",
    "            filtered_docs.append(d)\n",
    "        else:\n",
    "            print(\"---GRADE: DOCUMENT NOT RELEVANT---\")\n",
    "            continue\n",
    "    return {\"documents\": filtered_docs, \"question\": question}\n",
    "\n",
    "### Nodes\n",
    "def generate(state: GraphState):\n",
    "    \"\"\"\n",
    "    Generate a code solution\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, generation\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---GENERATING CODE SOLUTION---\")\n",
    "\n",
    "    # State\n",
    "    messages = state[\"messages\"]\n",
    "    iterations = state[\"iterations\"]\n",
    "    error = state[\"error\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    concatenated_content = format_docs(documents)\n",
    "    \n",
    "    # We have been routed back to generation with an error\n",
    "    if error == \"yes\":\n",
    "        messages += [\n",
    "            (\n",
    "                \"user\",\n",
    "                \"Now, try again. Invoke the code tool to structure the output with a prefix, imports, and code block:\",\n",
    "            )\n",
    "        ]\n",
    "\n",
    "    # Solution\n",
    "    code_solution = code_gen_chain_oai.invoke(\n",
    "        {\"context\": concatenated_content, \"messages\": messages}\n",
    "    )\n",
    "    messages += [\n",
    "        (\n",
    "            \"assistant\",\n",
    "            f\"{code_solution.prefix} \\n Imports: {code_solution.imports} \\n Code: {code_solution.code}\",\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # Increment\n",
    "    iterations = iterations + 1\n",
    "    return {\"generation\": code_solution, \"messages\": messages, \"iterations\": iterations}\n",
    "\n",
    "\n",
    "def code_check(state: GraphState):\n",
    "    \"\"\"\n",
    "    Check code\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, error\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---CHECKING CODE---\")\n",
    "\n",
    "    # State\n",
    "    messages = state[\"messages\"]\n",
    "    code_solution = state[\"generation\"]\n",
    "    iterations = state[\"iterations\"]\n",
    "    test_cases = state[\"test_cases\"]\n",
    "\n",
    "    # Get solution components\n",
    "    imports = code_solution.imports\n",
    "    code = code_solution.code\n",
    "    examples = test_cases\n",
    "\n",
    "    # Check imports\n",
    "    try:\n",
    "        exec(imports)\n",
    "    except Exception as e:\n",
    "        print(\"---CODE IMPORT CHECK: FAILED---\")\n",
    "        error_message = [(\"user\", f\"Your solution failed the import test: {str(e)}\")]\n",
    "        messages += error_message\n",
    "        return {\n",
    "            \"generation\": code_solution,\n",
    "            \"messages\": messages,\n",
    "            \"iterations\": iterations,\n",
    "            \"error\": \"yes\",\n",
    "        }\n",
    "\n",
    "    # Save the code to a file called test_code.py\n",
    "    file_name = 'test_code_w_examples.py'\n",
    "    with open(file_name, 'w') as f:\n",
    "        f.write(imports + \"\\n\" + code + \"\\n\" + examples)\n",
    "    \n",
    "    # Check execution\n",
    "\n",
    "    # Run the script file using subprocess\n",
    "    result = subprocess.run(['python', file_name], capture_output=True, text=True)\n",
    "    \n",
    "    # Check if there was an error\n",
    "    if result.returncode != 0:\n",
    "        print(\"An error occurred:\")\n",
    "        print(result.stderr)  # stderr will contain the traceback\n",
    "        \n",
    "        e = result.stderr\n",
    "        print(f\"Failed to run the script: {e}\")\n",
    "        print(\"---EXAMPLES BLOCK CHECK: FAILED---\")\n",
    "\n",
    "        error_message = [(\"user\", f\"Your solution failed the test case execution: {e}\")]\n",
    "        messages += error_message\n",
    "        return {\n",
    "            \"generation\": code_solution,\n",
    "            \"messages\": messages,\n",
    "            \"iterations\": iterations,\n",
    "            \"error\": \"yes\",\n",
    "        }\n",
    "\n",
    "\n",
    "    # No errors\n",
    "    print(\"---NO EXAMPLE TEST FAILURES---\")\n",
    "    return {\n",
    "        \"generation\": code_solution,\n",
    "        \"messages\": messages,\n",
    "        \"iterations\": iterations,\n",
    "        \"error\": \"no\",\n",
    "    }\n",
    "\n",
    "\n",
    "def reflect(state: GraphState):\n",
    "    \"\"\"\n",
    "    Reflect on errors\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, generation\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---GENERATING CODE SOLUTION---\")\n",
    "\n",
    "    # State\n",
    "    messages = state[\"messages\"]\n",
    "    iterations = state[\"iterations\"]\n",
    "    code_solution = state[\"generation\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    concatenated_content = format_docs(documents)\n",
    "\n",
    "    # Prompt reflection\n",
    "    messages += [\n",
    "            (\n",
    "                \"user\",\n",
    "                \"Reflect on the previous error and code:\",\n",
    "            )\n",
    "        ]\n",
    "\n",
    "    # Add reflection\n",
    "    reflections = code_gen_chain_oai.invoke(\n",
    "        {\"context\": concatenated_content, \"messages\": messages}\n",
    "    )\n",
    "    messages += [(\"assistant\", f\"Here are reflections on the error: {reflections}\")]\n",
    "    return {\"generation\": code_solution, \"messages\": messages, \"iterations\": iterations}\n",
    "\n",
    "# Edges\n",
    "def decide_to_finish(state: GraphState):\n",
    "    \"\"\"\n",
    "    Determines whether to finish.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        str: Next node to call\n",
    "    \"\"\"\n",
    "    error = state[\"error\"]\n",
    "    iterations = state[\"iterations\"]\n",
    "\n",
    "    if error == \"no\" or iterations == max_iterations:\n",
    "        print(\"---DECISION: FINISH---\")\n",
    "        return \"end\"\n",
    "    else:\n",
    "        print(\"---DECISION: RE-TRY SOLUTION---\")\n",
    "        if flag == \"reflect\":\n",
    "            return \"reflect\"\n",
    "        else:\n",
    "            return \"generate\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6fb1e15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END, StateGraph, START\n",
    "\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "# Define the nodes\n",
    "workflow.add_node(\"generate\", generate)  # generation solution\n",
    "workflow.add_node(\"grade_documents\", grade_documents)  # grade documents\n",
    "workflow.add_node(\"retrieve\", retrieve)  # retrieve\n",
    "workflow.add_node(\"check_code\", code_check)  # check code\n",
    "workflow.add_node(\"reflect\", reflect)  # reflect\n",
    "\n",
    "# Build graph\n",
    "workflow.add_edge(START, \"retrieve\")\n",
    "workflow.add_edge(\"retrieve\", \"grade_documents\")\n",
    "workflow.add_edge(\"grade_documents\", \"generate\")\n",
    "workflow.add_edge(\"generate\", \"check_code\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"check_code\",\n",
    "    decide_to_finish,\n",
    "    {\n",
    "        \"end\": END,\n",
    "        \"reflect\": \"reflect\",\n",
    "        \"generate\": \"generate\",\n",
    "    },\n",
    ")\n",
    "workflow.add_edge(\"reflect\", \"retrieve\")\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55020a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_case_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8049137b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Max tries\n",
    "max_iterations = 10\n",
    "\n",
    "from initial_prompt import create_test_case_code, create_question\n",
    "\n",
    "# Reflect\n",
    "flag = \"reflect\" # flag = 'reflect'\n",
    "\n",
    "function_name = \"remove_duplicate_phrases_or_sentences\"\n",
    "description = \"Create an expression to remove duplicate sentences or phrases separated by punctuation.\"\n",
    "\n",
    "test_case_data = [\n",
    "        {\"input\": \"This is a sentence. This is a sentence.\", \"expected\": \"This is a sentence.\"},\n",
    "        {\"input\": \"This is a sentence.This is a sentence.\", \"expected\": \"This is a sentence.\"},\n",
    "        {\"input\": \"Hello, hello, hello\", \"expected\": \"Hello,\"},\n",
    "        {\"input\": \"a hard example . A hard example\", \"expected\": \"a hard example.\"}\n",
    "    ]\n",
    "\n",
    "\n",
    "\n",
    "test_case_code = create_test_case_code(function_name, test_case_data)\n",
    "\n",
    "question = create_question(function_name, description, test_case_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0cd4b582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---RETRIEVE---\n",
      "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
      "Create an expression to remove duplicate sentences or phrases seperated by punctuation.\n",
      "\n",
      "Create a function called: remove_duplicate_phrases_or_sentences.\n",
      "\n",
      "Test cases:\n",
      "0. {\"input\": \"This is a sentence. This is a sentence.\", \"expected\": \"This is a sentence.\"}\n",
      "1. {\"input\": \"This is a sentence.This is a sentence.\", \"expected\": \"This is a sentence.\"}\n",
      "2. {\"input\": \"Hello, hello, hello\", \"expected\": \"Hello,\"}\n",
      "3. {\"input\": \"a hard example . A hard example\", \"expected\": \"a hard example.\"}\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GENERATING CODE SOLUTION---\n",
      "---CHECKING CODE---\n",
      "An error occurred:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\rohan\\llm-agents\\code-assist-rag-agent\\test_code_examples.py\", line 46, in <module>\n",
      "    raise Exception(errors)\n",
      "Exception: Error: Expected 'This is a sentence.', but got 'This is a sentence\u0001'\n",
      "Error: Expected 'This is a sentence.', but got 'This is a sentence\u0001'\n",
      "Error: Expected 'Hello,', but got 'hello'\n",
      "Error: Expected 'a hard example.', but got '. A hard example'\n",
      "\n",
      "Failed to run the script: Traceback (most recent call last):\n",
      "  File \"c:\\Users\\rohan\\llm-agents\\code-assist-rag-agent\\test_code_examples.py\", line 46, in <module>\n",
      "    raise Exception(errors)\n",
      "Exception: Error: Expected 'This is a sentence.', but got 'This is a sentence\u0001'\n",
      "Error: Expected 'This is a sentence.', but got 'This is a sentence\u0001'\n",
      "Error: Expected 'Hello,', but got 'hello'\n",
      "Error: Expected 'a hard example.', but got '. A hard example'\n",
      "\n",
      "---EXAMPLES BLOCK CHECK: FAILED---\n",
      "---DECISION: RE-TRY SOLUTION---\n",
      "---GENERATING CODE SOLUTION---\n",
      "---RETRIEVE---\n",
      "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
      "Create an expression to remove duplicate sentences or phrases seperated by punctuation.\n",
      "\n",
      "Create a function called: remove_duplicate_phrases_or_sentences.\n",
      "\n",
      "Test cases:\n",
      "0. {\"input\": \"This is a sentence. This is a sentence.\", \"expected\": \"This is a sentence.\"}\n",
      "1. {\"input\": \"This is a sentence.This is a sentence.\", \"expected\": \"This is a sentence.\"}\n",
      "2. {\"input\": \"Hello, hello, hello\", \"expected\": \"Hello,\"}\n",
      "3. {\"input\": \"a hard example . A hard example\", \"expected\": \"a hard example.\"}\n",
      "\n",
      "Your solution failed the test case execution: Traceback (most recent call last):\n",
      "  File \"c:\\Users\\rohan\\llm-agents\\code-assist-rag-agent\\test_code_examples.py\", line 46, in <module>\n",
      "    raise Exception(errors)\n",
      "Exception: Error: Expected 'This is a sentence.', but got 'This is a sentence\u0001'\n",
      "Error: Expected 'This is a sentence.', but got 'This is a sentence\u0001'\n",
      "Error: Expected 'Hello,', but got 'hello'\n",
      "Error: Expected 'a hard example.', but got '. A hard example'\n",
      "\n",
      "\n",
      "Reflect on the previous error and code:\n",
      "\n",
      "Here are reflections on the error: prefix='The previous implementation attempted to use a regular expression to remove duplicate phrases or sentences by capturing them and using backreferences to identify duplicates. However, the approach failed due to incorrect handling of punctuation and case sensitivity, as well as improper substitution that left unexpected characters in the output. To correct this, we need a more robust approach that accurately handles punctuation, white spaces, and case sensitivity. The new strategy will involve splitting the input string into sentences or phrases based on punctuation, normalizing the case for comparison, and using a set to track unique phrases, rebuilding the string at the end. We will ensure the original punctuation is preserved where necessary.' imports='import re' code=\"def remove_duplicate_phrases_or_sentences(text):\\n    # Split text into phrases/sentences based on punctuation followed by space or end of line\\n    phrases = re.split(r'([.!?,]\\\\s|\\\\.$)', text)\\n    seen = set()\\n    result = []\\n\\n    for phrase in phrases:\\n        # Normalize the phrase to handle case sensitivity for comparison\\n        normalized = phrase.strip().lower()\\n        if normalized not in seen:\\n            seen.add(normalized)\\n            result.append(phrase.strip())\\n\\n    # Join the unique phrases back with appropriate punctuation\\n    return ' '.join(result).replace(' .', '.').replace(' ,', ',')\" examples=\"# Test cases\\nprint(remove_duplicate_phrases_or_sentences('This is a sentence. This is a sentence.'))  # Expected: 'This is a sentence.'\\nprint(remove_duplicate_phrases_or_sentences('This is a sentence.This is a sentence.'))  # Expected: 'This is a sentence.'\\nprint(remove_duplicate_phrases_or_sentences('Hello, hello, hello'))  # Expected: 'Hello,'\\nprint(remove_duplicate_phrases_or_sentences('a hard example . A hard example'))  # Expected: 'a hard example.'\"\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GRADE: DOCUMENT NOT RELEVANT---\n",
      "---GENERATING CODE SOLUTION---\n",
      "---CHECKING CODE---\n",
      "---NO EXAMPLE TEST FAILURES---\n",
      "---DECISION: FINISH---\n"
     ]
    }
   ],
   "source": [
    "\n",
    "solution = app.invoke({\n",
    "    \"messages\": [(\"user\", question)],\n",
    "    \"iterations\": 0,\n",
    "    \"error\":\"\", \n",
    "    \"test_cases\": test_case_code}, {\"recursion_limit\": 50})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8fcb7b40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All test cases passed successfully.\n"
     ]
    }
   ],
   "source": [
    "!python test_code_w_examples.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "00f6fcc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'error': 'no',\n",
       " 'messages': [('user',\n",
       "   'Create an expression to remove duplicate sentences or phrases seperated by punctuation.\\n\\nCreate a function called: remove_duplicate_phrases_or_sentences.\\n\\nTest cases:\\n0. {\"input\": \"This is a sentence. This is a sentence.\", \"expected\": \"This is a sentence.\"}\\n1. {\"input\": \"This is a sentence.This is a sentence.\", \"expected\": \"This is a sentence.\"}\\n2. {\"input\": \"Hello, hello, hello\", \"expected\": \"Hello,\"}\\n3. {\"input\": \"a hard example . A hard example\", \"expected\": \"a hard example.\"}'),\n",
       "  ('assistant',\n",
       "   \"The problem is to remove duplicate sentences or phrases from a string where these sentences or phrases are separated by punctuation such as periods, commas, or spaces. The challenge is to use a regular expression to identify and remove the duplicates while keeping the first occurrence intact. The approach is to use a regular expression to identify the repeated phrases or sentences and then remove them. This can be done by capturing the phrases or sentences in a group and using a backreference to identify duplicates. The pattern will consider punctuation as separators and will be case insensitive to handle varying capitalizations. We will use the `re.sub` function to substitute the duplicates with an empty string. The regular expression pattern will use non-capturing groups for punctuation and spaces to handle different types of separators. The resulting string will be stripped of extra spaces or punctuation. \\n Imports: import re \\n Code: def remove_duplicate_phrases_or_sentences(text):\\n    # The regular expression pattern to find duplicate sentences or phrases\\n    pattern = r'(?i)\\\\b([a-zA-Z ,]+?)([., ]|$)(?=.*\\\\b\\\\1\\\\b)'  # Case insensitive\\n    \\n    # Substitute duplicates with an empty string\\n    result = re.sub(pattern, '', text)\\n    \\n    # Clean up any extra spaces or punctuation left\\n    result = re.sub(r'\\\\s{2,}', ' ', result)  # remove extra spaces\\n    result = re.sub(r'([.,])\\\\s*$', '\\\\1', result)  # remove trailing punctuation\\n    \\n    return result.strip()\"),\n",
       "  ('user',\n",
       "   'Your solution failed the test case execution: Traceback (most recent call last):\\n  File \"c:\\\\Users\\\\rohan\\\\llm-agents\\\\code-assist-rag-agent\\\\test_code_examples.py\", line 46, in <module>\\n    raise Exception(errors)\\nException: Error: Expected \\'This is a sentence.\\', but got \\'This is a sentence\\x01\\'\\nError: Expected \\'This is a sentence.\\', but got \\'This is a sentence\\x01\\'\\nError: Expected \\'Hello,\\', but got \\'hello\\'\\nError: Expected \\'a hard example.\\', but got \\'. A hard example\\'\\n'),\n",
       "  ('user', 'Reflect on the previous error and code:'),\n",
       "  ('assistant',\n",
       "   'Here are reflections on the error: prefix=\\'The previous implementation attempted to use a regular expression to remove duplicate phrases or sentences by capturing them and using backreferences to identify duplicates. However, the approach failed due to incorrect handling of punctuation and case sensitivity, as well as improper substitution that left unexpected characters in the output. To correct this, we need a more robust approach that accurately handles punctuation, white spaces, and case sensitivity. The new strategy will involve splitting the input string into sentences or phrases based on punctuation, normalizing the case for comparison, and using a set to track unique phrases, rebuilding the string at the end. We will ensure the original punctuation is preserved where necessary.\\' imports=\\'import re\\' code=\"def remove_duplicate_phrases_or_sentences(text):\\\\n    # Split text into phrases/sentences based on punctuation followed by space or end of line\\\\n    phrases = re.split(r\\'([.!?,]\\\\\\\\s|\\\\\\\\.$)\\', text)\\\\n    seen = set()\\\\n    result = []\\\\n\\\\n    for phrase in phrases:\\\\n        # Normalize the phrase to handle case sensitivity for comparison\\\\n        normalized = phrase.strip().lower()\\\\n        if normalized not in seen:\\\\n            seen.add(normalized)\\\\n            result.append(phrase.strip())\\\\n\\\\n    # Join the unique phrases back with appropriate punctuation\\\\n    return \\' \\'.join(result).replace(\\' .\\', \\'.\\').replace(\\' ,\\', \\',\\')\" examples=\"# Test cases\\\\nprint(remove_duplicate_phrases_or_sentences(\\'This is a sentence. This is a sentence.\\'))  # Expected: \\'This is a sentence.\\'\\\\nprint(remove_duplicate_phrases_or_sentences(\\'This is a sentence.This is a sentence.\\'))  # Expected: \\'This is a sentence.\\'\\\\nprint(remove_duplicate_phrases_or_sentences(\\'Hello, hello, hello\\'))  # Expected: \\'Hello,\\'\\\\nprint(remove_duplicate_phrases_or_sentences(\\'a hard example . A hard example\\'))  # Expected: \\'a hard example.\\'\"'),\n",
       "  ('user',\n",
       "   'Now, try again. Invoke the code tool to structure the output with a prefix, imports, and code block:'),\n",
       "  ('assistant',\n",
       "   \"The previous solution attempted to remove duplicate phrases using regular expressions but did not handle punctuation and case correctly. The revised approach involves splitting the input text into phrases or sentences using punctuation as delimiters, normalizing the case for comparison, and using a set to store unique phrases. We then reconstruct the result while preserving the original punctuation. This ensures that duplicates are removed effectively while maintaining the integrity of the original punctuation in the sentence. \\n Imports: import re \\n Code: def remove_duplicate_phrases_or_sentences(text):\\n    # Split text into phrases/sentences based on punctuation followed by space or end of line\\n    # and keep the delimiters as part of the split results\\n    phrases = re.split(r'(\\\\s*[.!?,]\\\\s*|\\\\.$)', text)\\n    seen = set()\\n    result = []\\n\\n    for phrase in phrases:\\n        # Normalize the phrase to handle case sensitivity for comparison\\n        normalized = phrase.strip().lower()\\n        if normalized and normalized not in seen:\\n            seen.add(normalized)\\n            result.append(phrase.strip())\\n\\n    # Join the unique phrases back with appropriate punctuation\\n    return ''.join(result)\")],\n",
       " 'generation': code(prefix='The previous solution attempted to remove duplicate phrases using regular expressions but did not handle punctuation and case correctly. The revised approach involves splitting the input text into phrases or sentences using punctuation as delimiters, normalizing the case for comparison, and using a set to store unique phrases. We then reconstruct the result while preserving the original punctuation. This ensures that duplicates are removed effectively while maintaining the integrity of the original punctuation in the sentence.', imports='import re', code=\"def remove_duplicate_phrases_or_sentences(text):\\n    # Split text into phrases/sentences based on punctuation followed by space or end of line\\n    # and keep the delimiters as part of the split results\\n    phrases = re.split(r'(\\\\s*[.!?,]\\\\s*|\\\\.$)', text)\\n    seen = set()\\n    result = []\\n\\n    for phrase in phrases:\\n        # Normalize the phrase to handle case sensitivity for comparison\\n        normalized = phrase.strip().lower()\\n        if normalized and normalized not in seen:\\n            seen.add(normalized)\\n            result.append(phrase.strip())\\n\\n    # Join the unique phrases back with appropriate punctuation\\n    return ''.join(result)\", examples=\"# Test cases\\nprint(remove_duplicate_phrases_or_sentences('This is a sentence. This is a sentence.'))  # Expected: 'This is a sentence.'\\nprint(remove_duplicate_phrases_or_sentences('This is a sentence.This is a sentence.'))  # Expected: 'This is a sentence.'\\nprint(remove_duplicate_phrases_or_sentences('Hello, hello, hello'))  # Expected: 'Hello,'\\nprint(remove_duplicate_phrases_or_sentences('a hard example . A hard example'))  # Expected: 'a hard example.'\"),\n",
       " 'iterations': 2,\n",
       " 'documents': [Document(metadata={'description': 'Source code: Lib/re/ This module provides regular expression matching operations similar to those found in Perl. Both patterns and strings to be searched can be Unicode strings ( str) as well as 8-...', 'language': 'en', 'source': 'https://docs.python.org/3/library/re.html', 'title': 're â\\x80\\x94 Regular expression operations — Python 3.13.0 documentation'}, page_content=\"See also\\nThe third-party regex module,\\nwhich has an API compatible with the standard library re module,\\nbut offers additional functionality and a more thorough Unicode support.\\n\\n\\nRegular Expression SyntaxÂ¶\\nA regular expression (or RE) specifies a set of strings that matches it; the\\nfunctions in this module let you check if a particular string matches a given\\nregular expression (or if a given regular expression matches a particular\\nstring, which comes down to the same thing).\\nRegular expressions can be concatenated to form new regular expressions; if A\\nand B are both regular expressions, then AB is also a regular expression.\\nIn general, if a string p matches A and another string q matches B, the\\nstring pq will match AB.  This holds unless A or B contain low precedence\\noperations; boundary conditions between A and B; or have numbered group\\nreferences.  Thus, complex expressions can easily be constructed from simpler\\nprimitive expressions like the ones described here.  For details of the theory\\nand implementation of regular expressions, consult the Friedl book [Frie09],\\nor almost any textbook about compiler construction.\\nA brief explanation of the format of regular expressions follows.  For further\\ninformation and a gentler presentation, consult the Regular Expression HOWTO.\\nRegular expressions can contain both special and ordinary characters. Most\\nordinary characters, like 'A', 'a', or '0', are the simplest regular\\nexpressions; they simply match themselves.  You can concatenate ordinary\\ncharacters, so last matches the string 'last'.  (In the rest of this\\nsection, weâ\\x80\\x99ll write REâ\\x80\\x99s in this special style, usually without quotes, and\\nstrings to be matched 'in single quotes'.)\\nSome characters, like '|' or '(', are special. Special\\ncharacters either stand for classes of ordinary characters, or affect\\nhow the regular expressions around them are interpreted.\\nRepetition operators or quantifiers (*, +, ?, {m,n}, etc) cannot be\\ndirectly nested. This avoids ambiguity with the non-greedy modifier suffix\\n?, and with other modifiers in other implementations. To apply a second\\nrepetition to an inner repetition, parentheses may be used. For example,\\nthe expression (?:a{6})* matches any multiple of six 'a' characters.\\nThe special characters are:\\n\\n.(Dot.)  In the default mode, this matches any character except a newline.  If\\nthe DOTALL flag has been specified, this matches any character\\nincluding a newline.  (?s:.) matches any character regardless of flags.\\n\\n\\n\\n^(Caret.)  Matches the start of the string, and in MULTILINE mode also\\nmatches immediately after each newline.\\n\\n\\n\\n$Matches the end of the string or just before the newline at the end of the\\nstring, and in MULTILINE mode also matches before a newline.  foo\\nmatches both â\\x80\\x98fooâ\\x80\\x99 and â\\x80\\x98foobarâ\\x80\\x99, while the regular expression foo$ matches\\nonly â\\x80\\x98fooâ\\x80\\x99.  More interestingly, searching for foo.$ in 'foo1\\\\nfoo2\\\\n'\\nmatches â\\x80\\x98foo2â\\x80\\x99 normally, but â\\x80\\x98foo1â\\x80\\x99 in MULTILINE mode; searching for\\na single $ in 'foo\\\\n' will find two (empty) matches: one just before\\nthe newline, and one at the end of the string.\\n\\n\\n\\n*Causes the resulting RE to match 0 or more repetitions of the preceding RE, as\\nmany repetitions as are possible.  ab* will match â\\x80\\x98aâ\\x80\\x99, â\\x80\\x98abâ\\x80\\x99, or â\\x80\\x98aâ\\x80\\x99 followed\\nby any number of â\\x80\\x98bâ\\x80\\x99s.\\n\\n\\n\\n+Causes the resulting RE to match 1 or more repetitions of the preceding RE.\\nab+ will match â\\x80\\x98aâ\\x80\\x99 followed by any non-zero number of â\\x80\\x98bâ\\x80\\x99s; it will not\\nmatch just â\\x80\\x98aâ\\x80\\x99.\"),\n",
       "  Document(metadata={'description': 'Source code: Lib/re/ This module provides regular expression matching operations similar to those found in Perl. Both patterns and strings to be searched can be Unicode strings ( str) as well as 8-...', 'language': 'en', 'source': 'https://docs.python.org/3/library/re.html', 'title': 're â\\x80\\x94 Regular expression operations — Python 3.13.0 documentation'}, page_content='re â\\x80\\x94 Regular expression operations — Python 3.13.0 documentation\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    Theme\\n    \\nAuto\\nLight\\nDark\\n\\n\\n\\nTable of Contents\\n\\nre â\\x80\\x94 Regular expression operations\\nRegular Expression Syntax\\nModule Contents\\nFlags\\nFunctions\\nExceptions\\n\\n\\nRegular Expression Objects\\nMatch Objects\\nRegular Expression Examples\\nChecking for a Pair\\nSimulating scanf()\\nsearch() vs. match()\\nMaking a Phonebook\\nText Munging\\nFinding all Adverbs\\nFinding all Adverbs and their Positions\\nRaw String Notation\\nWriting a Tokenizer\\n\\n\\n\\n\\n\\n\\n\\nPrevious topic\\nstring â\\x80\\x94 Common string operations\\n\\n\\nNext topic\\ndifflib â\\x80\\x94 Helpers for computing deltas\\n\\n\\nThis Page\\n\\nReport a Bug\\n\\nShow Source\\n        \\n\\n\\n\\n\\n\\n\\n\\nNavigation\\n\\n\\nindex\\n\\nmodules |\\n\\nnext |\\n\\nprevious |\\n\\nPython »\\n\\n\\n\\n\\n\\n\\n\\n3.13.0 Documentation »\\n    \\nThe Python Standard Library »\\nText Processing Services »\\nre â\\x80\\x94 Regular expression operations\\n\\n\\n\\n\\n\\n\\n\\n                     |\\n                \\n\\n\\n    Theme\\n    \\nAuto\\nLight\\nDark\\n\\n |\\n\\n\\n\\n\\n\\n\\n\\nre â\\x80\\x94 Regular expression operationsÂ¶\\nSource code: Lib/re/\\n\\nThis module provides regular expression matching operations similar to\\nthose found in Perl.\\nBoth patterns and strings to be searched can be Unicode strings (str)\\nas well as 8-bit strings (bytes).\\nHowever, Unicode strings and 8-bit strings cannot be mixed:\\nthat is, you cannot match a Unicode string with a bytes pattern or\\nvice-versa; similarly, when asking for a substitution, the replacement\\nstring must be of the same type as both the pattern and the search string.\\nRegular expressions use the backslash character (\\'\\\\\\') to indicate\\nspecial forms or to allow special characters to be used without invoking\\ntheir special meaning.  This collides with Pythonâ\\x80\\x99s usage of the same\\ncharacter for the same purpose in string literals; for example, to match\\na literal backslash, one might have to write \\'\\\\\\\\\\\\\\\\\\' as the pattern\\nstring, because the regular expression must be \\\\\\\\, and each\\nbackslash must be expressed as \\\\\\\\ inside a regular Python string\\nliteral. Also, please note that any invalid escape sequences in Pythonâ\\x80\\x99s\\nusage of the backslash in string literals now generate a SyntaxWarning\\nand in the future this will become a SyntaxError. This behaviour\\nwill happen even if it is a valid escape sequence for a regular expression.\\nThe solution is to use Pythonâ\\x80\\x99s raw string notation for regular expression\\npatterns; backslashes are not handled in any special way in a string literal\\nprefixed with \\'r\\'.  So r\"\\\\n\" is a two-character string containing\\n\\'\\\\\\' and \\'n\\', while \"\\\\n\" is a one-character string containing a\\nnewline.  Usually patterns will be expressed in Python code using this raw\\nstring notation.\\nIt is important to note that most regular expression operations are available as\\nmodule-level functions and methods on\\ncompiled regular expressions.  The functions are shortcuts\\nthat donâ\\x80\\x99t require you to compile a regex object first, but miss some\\nfine-tuning parameters.\\n\\nSee also\\nThe third-party regex module,\\nwhich has an API compatible with the standard library re module,\\nbut offers additional functionality and a more thorough Unicode support.')],\n",
       " 'test_cases': '\\n\\nerrors = []\\n\\n\\n# Test case 1\\noutput = remove_duplicate_phrases_or_sentences(\"This is a sentence. This is a sentence.\")\\nif output != \"This is a sentence.\":\\n    err = f\"Error: Expected \\'This is a sentence.\\', but got \\'{output}\\'\"\\n    errors.append(err)\\n\\n# Test case 2\\noutput = remove_duplicate_phrases_or_sentences(\"This is a sentence.This is a sentence.\")\\nif output != \"This is a sentence.\":\\n    err = f\"Error: Expected \\'This is a sentence.\\', but got \\'{output}\\'\"\\n    errors.append(err)\\n\\n# Test case 3\\noutput = remove_duplicate_phrases_or_sentences(\"Hello, hello, hello\")\\nif output != \"Hello,\":\\n    err = f\"Error: Expected \\'Hello,\\', but got \\'{output}\\'\"\\n    errors.append(err)\\n\\n# Test case 4\\noutput = remove_duplicate_phrases_or_sentences(\"a hard example . A hard example\")\\nif output != \"a hard example.\":\\n    err = f\"Error: Expected \\'a hard example.\\', but got \\'{output}\\'\"\\n    errors.append(err)\\n\\n\\nerrors = \"\\\\n\".join(errors)\\nif errors:\\n    raise Exception(errors)\\nelse:\\n    print(\"All test cases passed successfully.\")'}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solution"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
